version: '3'
services:
    hadoop_master:
        build: 
            context: ./dockerfiles
            dockerfile: docker-hadoop
        hostname: 'namenode'
        container_name: 'hadoop-master'
        restart: always
        depends_on:
            - hadoop_slave1
            - resourcemanager
            - nodemanager
            - historyserver
        ports:
            - 9870:9870
            - 9000:9000
        volumes:
            - ./data/hadoop_yarn/dfs/master/namenode:/hadoop/dfs/name
            - ./data/hadoop_yarn/output/master:/user_data
        environment:
            - CLUSTER_NAME=Stock_Project 
        env_file:
            - ./env/hadoop_yarn/hadoop.env
        command:
            - "hdfs namenode -rollingUpgrade started"

    hadoop_slave1:
        build:                 
            context: ./dockerfiles
            dockerfile: docker-hadoop-slave
        hostname: 'datanode'
        container_name: 'hadoop-slave1'
        restart: always
        volumes:
            - ./data/hadoop_yarn/output/slave1:/user_data
            - ./data/hadoop_yarn/dfs/slave1/datanode:/hadoop/dfs/data
        environment:
            - SERVICE_PRECONDITION=namenode:9870
        env_file:
            - ./env/hadoop_yarn/hadoop.env

    resourcemanager:
        image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
        container_name: yarn-resourcemanager
        restart: always
        ports:
            - 8088:8088
        environment:
            - SERVICE_PRECONDITION=namenode:9870 namenode:9000 datanode:9864
        env_file:
            - ./env/hadoop_yarn/hadoop.env

    nodemanager:
        image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
        container_name: yarn-nodemanager
        restart: always
        environment:
            - SERVICE_PRECONDITION=namenode:9870 namenode:9000 datanode:9864 resourcemanager:8088
        env_file:
            - ./env/hadoop_yarn/hadoop.env
  
    historyserver:
        image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
        container_name: yarn-historyserver
        restart: always
        environment:
            - SERVICE_PRECONDITION=namenode:9870 namenode:9000 datanode:9864 resourcemanager:8088
        volumes:
            - ./hadoop/yarn_historyserver:/hadoop/yarn/timeline
        env_file:
            - ./env/hadoop_yarn/hadoop.env

    spark-master:
        build: 
            context: ./dockerfiles
            dockerfile: docker-spark
        hostname: 'spark-master'
        container_name: 'spark-master'
        depends_on:
            - hadoop_master
            - hadoop_slave1
            - resourcemanager
            - nodemanager
            - historyserver

        ports:
            - 7077:7077 # spark master context
            - 8080:8080 # spark jobs history
        environment:
            - INIT_DAEMON_STEP=setup_spark
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
        working_dir: /spark/bin

    spark-worker-1:
        build:  
            context: ./dockerfiles
            dockerfile: docker-spark
        container_name: 'spark-worker-1'
        depends_on:
            - spark-master
        ports:
            - 8081:8081 # spark 
        environment:
            - SPARK_MASTER=spark://spark-master:7077
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000

    spark-worker-2:
        build:  
            context: ./dockerfiles
            dockerfile: docker-spark
        container_name: spark-worker-2
        depends_on:
            - spark-master
        ports:
            - 8082:8081 # spark 
        environment:
            - SPARK_MASTER=spark://spark-master:7077
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000

    spark-worker-3:
        build:  
            context: ./dockerfiles
            dockerfile: docker-spark
        container_name: spark-worker-3
        depends_on:
            - spark-master
        ports:
            - 8083:8081 # spark 
        environment:
            - SPARK_MASTER=spark://spark-master:7077
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000


    mysql:
        build:  
            context: ./dockerfiles
            dockerfile: docker-mysql
        hostname: 'mysql'
        container_name: 'mysql'
        restart: always
        ports:
            - 3306:3306 # mysqld
        volumes:
            - ./data/mysql:/var/lib/mysql
        environment:
            - MYSQL_DATABASE=twstock
            - MYSQL_USER=teb101Club
            - MYSQL_PASSWORD=teb101Club
            - MYSQL_ROOT_PASSWORD=root

    flask:
        build:  
            context: ./dockerfiles
            dockerfile: docker-flask
        hostname: 'jupyter'
        container_name: 'jupyter'
        restart: unless-stopped
        ports:
            - 5000:5000 # flask
            - 8888:8888 # jupyter
        volumes:
            - ./data/flask/code:/home/jovyan/work

